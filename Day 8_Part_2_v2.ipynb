{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **`Part II`**"
      ],
      "metadata": {
        "id": "rD89-nus4j4K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k343f0vLNTY"
      },
      "source": [
        "### Conduct Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YnMyCQ4LUx9"
      },
      "source": [
        "Sentiment Analysis which focuses on analyzing sentiment of various text resources ranging from corporate feedback surveys to movie reviews is probably the most popular application of text analytics. The main aspect of sentiment analysis is to analyze a body of text in order to decipher the opinion expressed by it including factors like emotion, feelings and mood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5iB3-ub0NSa"
      },
      "source": [
        "**When does \"Sentiment Analysis\" work best?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4OY2dsh0WrE"
      },
      "source": [
        "\n",
        "Sentiment Analysis works best on text that has a subjective context rather than an objective context. When a body of text has an objective perspective, it usually reflects real factual statements with no emotion or feelings associated with it. In contrast, subjective text includes opinions encompassing emotions and feelings that are expressed by humans. Given the proliferation of social media channels, Sentiment Analysis is increasingly being leveraged by a host of entities (be it a business, a public sector organization, government, etc.) to extract the subjective and opinion related information like emotions, attitude, mood and use the extracted subjective information to the detect the sentiment of people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwj1cZJh0xRk"
      },
      "source": [
        "**What is covered in this objective?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-NA-PsS0anP"
      },
      "source": [
        "In a nutshell, sentiment analysis can be defined as a classification problem in which the classification is either —binary classification (positive or negative) and multi-class classification (positive, negative, or neutral).\n",
        "\n",
        "Within this objective, we will explore a range of related topics encompassing **1)** Constructing a Sentiment Analysis Model, **2)** Determining the subjectivity of text, **3)** Examining the intensity or polarity of a sentiment and **4)** Performing sentiment analysis on tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntPfbgJP1lKj"
      },
      "source": [
        "**Utilize a Sentiment Dictionary to decipher the sentiment of text**\n",
        "\n",
        "A sentiment dictionary is the mapping of words to sentiment values. For example: the word awesome (which is a positive sentiment) could have a value of +3.7 and the word horrible (which is a negative sentiment) could have a value of -3.1. While using a sentiment dictionary, the values of the sentiment words are summed to get the overall sentiment of the text.\n",
        "\n",
        "For example: I loved the ambience of the restaurant but the drive to the restaurant was horrendous. Overall, it was a good evening.\n",
        "\n",
        "Now let's say the value of the word love is +3.9, the value of the word horrendous is -4.2 and the value of the word good is +2.9. So, the overall sentiment of the text is positive since the aggregate of the values of the sentiment words is positive.\n",
        "\n",
        "To decipher the sentiment of text, we will utilize NLTK's **VADER** Sentiment Tool. VADER stands for Valence Aware Dictionary for Sentiment Reasoning. The dictionary was designed specifically for Twitter and contains emoticons and slang. **It also provides support for sentiment intensifiers  (words such as incredibly funny) and negations (words such as \"not bad\" which is a slight/small positive sentiment)**.\n",
        "\n",
        "How it works? VADER analyzes a piece of text to check if any of the words in the text are present in the lexicon. It  produces 4 sentiment metrics from the word ratings i.e. positive, neutral, negative and compound. The compound score is the sum of all of the lexicon ratings which is standardized to a range between -1 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J12Z1F_MJnev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045a1918-a55a-4f81-8066-5ea17c72a3f8"
      },
      "source": [
        "# Install the VADER Sentiment Tool\n",
        "\n",
        "!pip install vaderSentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FzqveioJyRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60351462-3fa1-4c91-c717-e0643ae75cc6"
      },
      "source": [
        "#Load the SentimentIntensityAnalyzer object from the VADER package\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "#Create a handle to the SentimentIntensityAnalyzer object\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "#function that outputs the sentiment ratings\n",
        "def print_sentiment_ratings(sentence):\n",
        "    sent = analyzer.polarity_scores(sentence)\n",
        "    print(\"{} {}\".format(sentence, sent))\n",
        "\n",
        "#Examining the sentiment ratings for different pieces of text\n",
        "#No sentiment expressed\n",
        "\n",
        "print_sentiment_ratings(\"I have to work on the weekend\")\n",
        "\n",
        "#Overall rating is neutral"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have to work on the weekend {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDQlgUieLJss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1b3928-0fb0-49a7-c714-e11e7d286ae4"
      },
      "source": [
        "#Sentiment expressed via emoticon\n",
        "\n",
        "print_sentiment_ratings(\"I have to work on the weekend :(\")\n",
        "\n",
        "#Overall rating is negative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have to work on the weekend :( {'neg': 0.293, 'neu': 0.707, 'pos': 0.0, 'compound': -0.4404}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_xiNhzLhpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5df6edf-ef7b-4af7-de2c-f9a292b9e2bd"
      },
      "source": [
        "#Expressing a more intense feeling via 2 emoticons\n",
        "\n",
        "print_sentiment_ratings(\"I have to work on the weekend :( :(\")\n",
        "\n",
        "#Overall rating is even more negative than the above piece of text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have to work on the weekend :( :( {'neg': 0.453, 'neu': 0.547, 'pos': 0.0, 'compound': -0.7003}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WClSIBHHL1q-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73db881a-dfcf-47ee-cf22-39fe5af35862"
      },
      "source": [
        "#VADER handles emotion intensifiers (i.e. words such as very, really, super, etc.)\n",
        "\n",
        "print_sentiment_ratings(\"I did well on the test\")\n",
        "\n",
        "#The sentiment rating for the sentence below is higher than the one above\n",
        "\n",
        "print_sentiment_ratings(\"I did very well on the test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I did well on the test {'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'compound': 0.2732}\n",
            "I did very well on the test {'neg': 0.0, 'neu': 0.715, 'pos': 0.285, 'compound': 0.3384}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feLIyvQ9L8wR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca4ea6b-2706-4463-c0b7-95f7dd4eb813"
      },
      "source": [
        "#VADER takes into consideration how the words are written - capitalization has an impact on the sentiment ratings\n",
        "\n",
        "print_sentiment_ratings(\"I had a super day\")\n",
        "\n",
        "#The sentiment rating for the sentence below is higher than the one above\n",
        "\n",
        "print_sentiment_ratings(\"I had a SUPER day\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I had a super day {'neg': 0.0, 'neu': 0.506, 'pos': 0.494, 'compound': 0.5994}\n",
            "I had a SUPER day {'neg': 0.0, 'neu': 0.463, 'pos': 0.537, 'compound': 0.6841}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJbkEr21MFz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db46d6a1-e0ab-431a-cd69-ff2248cd9153"
      },
      "source": [
        "#Finally, VADER handles changes in sentiment intensity; specifically when a sentence contains the word \"but\". Higher weighting is given to the sentiment after the word \"but\".\n",
        "#The overall rating for the sentence below is negative\n",
        "\n",
        "print_sentiment_ratings(\" I loved the ambience of the restaurant but the drive to the restaurant was horrendous\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I loved the ambience of the restaurant but the drive to the restaurant was horrendous {'neg': 0.252, 'neu': 0.63, 'pos': 0.119, 'compound': -0.5789}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWMCi3alY2em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085af340-fee6-49d1-a6e5-443f0813234a"
      },
      "source": [
        "!pip install -U textblob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (4.66.4)\n",
            "Installing collected packages: textblob\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.17.1\n",
            "    Uninstalling textblob-0.17.1:\n",
            "      Successfully uninstalled textblob-0.17.1\n",
            "Successfully installed textblob-0.18.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY1_JmvfY75D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a37363-7053-41bb-8be8-c8b0596b4814"
      },
      "source": [
        "!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueX7EWVJXi3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bebc07-96b2-4fcc-fa9e-c39474e24a0a"
      },
      "source": [
        "#Test drive TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "#Initialize a variable\n",
        "txtblob = TextBlob(\"Lambda School is dreadful.\")\n",
        "\n",
        "#Get the POS\n",
        "#txtblob.tags\n",
        "\n",
        "#Get the polarity of the sentiment\n",
        "txtblob.polarity\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fZux5MUeNaZ",
        "outputId": "7dfd9708-cbee-4b60-8d31-ddf4997e84b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=b6483ce3336795c89287ed354557247bb98c5b0f4cf68173e80ed352ba6cda0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWQJ_L3yf0jM",
        "outputId": "f03480ee-27fa-461f-976b-257efcf6320c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from pyspark import SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "d08TOl1ef4CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Function to generate a simulated data stream\n",
        "def generate_stream(max_iterations=10):\n",
        "    import time\n",
        "    import random\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # Generate random data\n",
        "        data = (random.randint(1, 10), random.random())\n",
        "        yield data\n",
        "        time.sleep(1)  # Simulate 1 second interval between data points\n",
        "\n",
        "    print(\"Reached maximum number of iterations. Stopping stream.\")\n",
        "\n",
        "# Check if a SparkContext already exists\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# If no SparkContext exists, create a new one\n",
        "if sc is None:\n",
        "    sc = SparkContext(\"local[*]\", \"SparkStreamingDemo\")\n",
        "\n",
        "# Create a StreamingContext with batch interval of 5 seconds\n",
        "ssc = StreamingContext(sc, 5)\n",
        "\n",
        "# Create a DStream from the simulated data stream\n",
        "stream = ssc.queueStream([generate_stream()])\n",
        "\n",
        "# Process the data stream\n",
        "stream.foreachRDD(lambda rdd: print(rdd.collect()))\n",
        "\n",
        "# Start the streaming context\n",
        "ssc.start()\n",
        "\n",
        "# Wait for the streaming to finish\n",
        "ssc.awaitTerminationOrTimeout(30)  # Stop after 30 seconds, in case for some unexpected execution delays\n",
        "\n",
        "# Stop the streaming context\n",
        "ssc.stop(stopSparkContext=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwhswVoTdKjJ",
        "outputId": "e765359a-2847-42b1-e72c-b14cbf68148d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached maximum number of iterations. Stopping stream.\n",
            "[(9, 0.2560046458826183), (9, 0.08402663900363261), (9, 0.32449373782571045), (2, 0.9124250198300456), (8, 0.14505745639498924), (9, 0.13218739909292931), (4, 0.11740313072434883), (3, 0.5881328634181099), (3, 0.24361625082552307), (4, 0.4970356207987032)]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "* Set up PySpark in Google Colab: Install the necessary dependencies and initialize PySpark.\n",
        "Create a Data Streaming Script: A Python script that simulates streaming data by sending random values to a socket.\n",
        "PySpark Streaming Code: Set up a streaming context in PySpark to read data from the socket and perform transformations."
      ],
      "metadata": {
        "id": "HoToLHf4IhRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In Class Project / Discussion\n",
        "**Objective**:<br>\n",
        "\n",
        "* **To show understanding of big data anlaytics**\n",
        "* **Instruction:**\n",
        "  *  3-4 students per group\n",
        "  *  work on a small project (any topic), but data is required in 1 hour\n",
        "  * KPIs:\n",
        "    * Team memember names:\n",
        "    * Topic/ Problem defination\n",
        "    * Why do you want to study this?\n",
        "    * Who are your audience?\n",
        "    * Study Design:\n",
        "      * Pipleline\n",
        "        * Data source\n",
        "        * Data Defination\n",
        "        * Size\n",
        "      * Methodology\n",
        "        * EDA\n",
        "        * Model\n",
        "      * Analysis\n",
        "      * Conclusion\n",
        "      * Limitation\n",
        "* **Evaluation Criteria**\n",
        "  * Each group has 10-12 minutes for the presentation. (`50 point`)\n",
        "  * Each group member should have at least one slide to present. (`10 point`)\n",
        "  * Pre-presentation:\n",
        "    * Post group project's outline or content in Canvas/ Day 8 Discussion (`20 pints`)\n",
        "  * Post-presentation:\n",
        "    * Comment other group presentatino in Canvas / Day 8 Discussion (`20 points`)<br>\n",
        "\n",
        "\n",
        "**Please note** that your comments should be professional and insightful, meaning you should avoid using phrases like 'I agree with you' or 'Yes, you are right,' as well as any non-respectful comments.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "781rXfyqHL_C"
      }
    }
  ]
}
